{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml_parse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yaml_parse.fill_gaps()\n",
    "# yaml_parse.save_contents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The data consists of 10 observations. Bla, Bla, ...."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown as md\n",
    "# Instead of setting the cell to Markdown, create Markdown from withnin a code cell!\n",
    "# We can just use python variable replacement syntax to make the text dynamic\n",
    "n = 10\n",
    "md(\"The data consists of {} observations. Bla, Bla, ....\".format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2021, 4, 24, 16, 52, 21, 809237)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "delt = datetime.timedelta(days=2)\n",
    "delt\n",
    "now - delt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no updates for  Oyster Vibrio Literature Review\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Data & Visualization Weekly Projects Report 2021_04_23\n",
       "\n",
       "## Active Projects \n",
       "\n",
       "\n",
       "### Active Development \n",
       "\n",
       "* Advice For Thesis Defense Visualizations, Sabrina Nardin \n",
       "\t * Met with Sabrina to discuss her dissertation defense's visualizations\n",
       "\t * Her data is visualizing 8 different violent events from Italy's history in the last 50 years covered by 3 different newspapers\n",
       "\t * Most of her questions were about how to improve her existing approaches so I laid out the foundation of \"task abstraction\" taught to me by Joshua Levine using Tamara Munzner's design theory for visualization\n",
       "\t * Shared resources with Sabrina and recommended a few changes, but overall tried to equip her with the ability to critique her own work\n",
       "\t * Mentioned other best practices such as sharing her visualizations with as many other people that are like her target audience as early as possible\n",
       "\t * Has asked for a follow up based on changes incorporated since the meeting\n",
       "* Biosphere 2 Biosystems Visualization Collaboration \n",
       "\t * Met with Omani, and started in a new direction\n",
       "\t * We will base our work on her photo realistic nature scene\n",
       "\t * Take models from it and convert into the 2 types of assets that I've identified in the tree-hugger video (pseudo lidar, dynamic point paths)\n",
       "\t * She asked to specifically learn more about shaders so I've started teaching that material using the shadertoy program, I should mention to her that touch is free for non commercial and perhaps it will run on her laptop\n",
       "\t * I have to decide what makes sense to do with the results that I already have from the Open Root Sim if we go in this direction\n",
       "\t * Ash Black was interested in this project in our meeting, perhaps find a way to make this into work that his students can take on\n",
       "* Data Visualization Roadshow With Jeff Oliver \n",
       "\t * Heard back from the NSCS department about a presentation\n",
       "\t * Just working on the date for the presentation\n",
       "\t * Presenting to undergraduates also\n",
       "* Independent Study Abby Collier \n",
       "\t * Had our usual friday meeting\n",
       "\t * Made quite a bit of progress on her feature Touch Designer piece called \"purple stars\"\n",
       "\t * Spent time working on her github webpage to present the work from this independent study\n",
       "\t * Talked about potential for her to continue in this capacity after graduation as a DCC\n",
       "* Judging The Data Visualization Challenge \n",
       "\t * Two more entries of 15 to judge, had a few issues with the rubric in the process\n",
       "\t * Likely will circle back just to make sure I'm executing my judging process consistently on some of the more nuanced scoring categories\n",
       "* Migrant Forensic Empathy Project: A Digital Borderlands Grant Initiative \n",
       "\t * Got answers about the visual artifacts on SO, sounds like it is a camera parameter issue, hopefully I can still resolve it using a shadeless environment texture\n",
       "\t * Re-implemented the quad tree algorithm to allow for subsection overlap, unfortunately this caused my recursive algorithm to stack overflow when I put greater limits on the number of elements per region\n",
       "\t * Re-learned some more advanced methods in rust that will allow me to write the \"populate quadtree\" and \"query\" algorithms without recursion\n",
       "\t * For the mean time, just started long running task and processed cross placements much more accurately\n",
       "\t * It's pretty heartbreaking to see the crosses that are right next to each other  https://test-cross-placement.baylyd.repl.co/\n",
       "* Oyster Vibrio Literature Review \n",
       "* Remote Visualization Infrastructure Development \n",
       "\t * Chris notified me that NoMachine was installed on i18n16, but there's firewall issues with port 4000 so I wasn't able to test this out\n",
       "\t * Met other members of the Omniverse team who are willing to help me when I run into issues with remote visualization for my projects\n",
       "\t * Tangentially related, I figured out how to render raw byte streams of data over TCP in the Touch Designer program which may be a personal method for doing remote visualization from simulations running on the HPC\n",
       "* Resbaz Organizer And Workshop Provider \n",
       "\t * Met Chinmay and we discussed some final todo items\n",
       "\t * Testing our links next week and publishing them to the website team\n",
       "\t * Noticed that my workshop still isn't listed on the resbaz page so I'll have to get in touch with Alex about that\n",
       "\t * Blake volunteered to perform the uploads to youtube so that's helpful, still haven't heard from Kelsey about whether our unlisted approach is going to be the correct way to go\n",
       "* Stellarscape Astronomy Multimedia Dance Performance \n",
       "\t * Worked out how to use the Engine COMP to start processes in other threads so that we can keep our visualization performance high\n",
       "\t * This enabled me to implement a TCP client that receives raw bytes and converts them to a texture that we can operate on with the GPU\n",
       "\t * I believe this will help me bring the HPC into the project in bigger ways\n",
       "\t * Spent more time learning how to create multi segment lines in the compute shader\n",
       "\n",
       "\n",
       "### Consultations \n",
       "\n",
       "* Advice For Thesis Defense Visualizations, Sabrina Nardin \n",
       "\n",
       "## Upcoming \n",
       "\n",
       "* Bryan Carter Photogrammetry \n",
       "* Collaboration With Techcore's Summer Internship \n",
       "* Has Faculty Collaborations With Holodeck \n",
       "* Jason Hortin Holographic Dance Graduate Project \n",
       "* Observablehq Portfolio Of Data Visualization \n",
       "* Ray Tracing On The Hpc \n",
       "\n",
       "\n",
       "## Completed For Fiscal Year \n",
       "\n",
       "\n",
       "\n",
       "### Workshops/Trainings \n",
       "\n",
       "* Mt. Lemmon In Your Pocket-Creating A Virtual Reality Tour \n",
       "\t * https://rtdatavis.github.io/#GIS_week2020 \n",
       "* Presentation For Civil Engineering Department \n",
       "\t * https://docs.google.com/presentation/d/15Z9zcxU4vIIgFPnKEcaGv9GH7JtjNdx4Xpnjec0EzEc/edit?usp=sharing \n",
       "* Tech Core Level Up Presentation Monday, Sept 28 2020 \n",
       "\t * https://rtdatavis.github.io/#techcoresept28 \n",
       "* Tech Core Level Up Presentation Tuesday, Mar 17 2020 \n",
       "\t * https://rtdatavis.github.io/#techcoremar20 \n",
       "* Womens Hackathon: Visualization On The Web Workshop \n",
       "\t * https://womenshackathon.arizona.edu/ \n",
       "\t * https://www.youtube.com/channel/UCe1YiJ53o3qcayVs4cipeXA/videos \n",
       "\t * https://www.youtube.com/watch?v=VLwPOtqW8oM \n",
       "\n",
       "\n",
       "### Completed Projects/Collaborations \n",
       "\n",
       "* 3D & Vr Retrofit Azlive \n",
       "\t * https://rtdatavis.github.io/#retrofitAZLIVE \n",
       "* Bio5 Virtual Reality Tour \n",
       "\t * https://rtdatavis.github.io/#bio5-vr-tour \n",
       "* Covid Retail Mitigation Web Scraping \n",
       "\t * https://rtdatavis.github.io/#retailscraping \n",
       "* Force Directed Biochem Networks \n",
       "\t * https://rtdatavis.github.io/#biochem-networks \n",
       "* Neuro Choropleth \n",
       "\t * https://rtdatavis.github.io/#neuro-choro \n",
       "* Spring Break Covid Photo Maps \n",
       "\t * https://rtdatavis.github.io/#spring-break-covid \n",
       "\n",
       "\n",
       "### Infrastructure Developed \n",
       "\n",
       "* Autamus Web Interface \n",
       "\t * https://rtdatavis.github.io/#autamus_interface \n",
       "* Virtualgl For Nvidia Accelerated Remote Hpc Visualizations \n",
       "\t * https://rtdatavis.github.io/#virtualgl \n",
       "* Xpra And Singularity For Comprehensive Graphical Application Support On Hpc \n",
       "\t * https://rtdatavis.github.io/#xprasingularity \n",
       "\n",
       "\n",
       "### Protocols and Analysis Developed \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import yaml\n",
    "from io import StringIO\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "def run():\n",
    "    now = datetime.datetime.now() - datetime.timedelta(days=3)\n",
    "    \n",
    "    with open(\"first_doc.yaml\",\"r\") as phile:\n",
    "        # projects\n",
    "        p = yaml.full_load(phile)\n",
    "    ophile = StringIO()\n",
    "    dc = p[\"detailed_collection\"]\n",
    "    ophile.write(f\"# Data & Visualization Weekly Projects Report {now:%Y}_{now:%m}_{now:%d}\\n\")\n",
    "    ophile.write(f\"\\n## Active Projects \\n\\n\")\n",
    "    ophile.write(f\"\\n### Active Development \\n\\n\")\n",
    "    for p_name_key in dc:\n",
    "        deets = dc[p_name_key]\n",
    "        #print(deets[\"status\"])\n",
    "        if deets[\"status\"] == \"active\":\n",
    "            ##print(\"details\",p_name_key,deets,\"\\n\\n\")\n",
    "            ophile.write(f\"* {p_name_key} \\n\")\n",
    "            ## go through the under points\n",
    "            ## this will be a nested list\n",
    "            #print(deets)\n",
    "            if deets[\"updates\"] != None and len(deets[\"updates\"]) > 0:\n",
    "                latest = deets[\"updates\"][0]\n",
    "                if not deets[\"newUpdates\"]:\n",
    "                    print(\"no updates for \",p_name_key)\n",
    "                    continue\n",
    "                for update in latest:\n",
    "                    ophile.write(f\"\\t * {update}\\n\")\n",
    "    ophile.write(f\"\\n\\n### Consultations \\n\\n\")\n",
    "    for p_name_key in dc:\n",
    "        deets = dc[p_name_key]\n",
    "        if deets[\"type\"] == \"consult\" and deets[\"status\"]== \"active\":\n",
    "            ophile.write(f\"* {p_name_key} \\n\")\n",
    "    ophile.write(f\"\\n## Upcoming \\n\\n\")\n",
    "    for p_name_key in dc:\n",
    "        deets = dc[p_name_key]\n",
    "        if deets[\"status\"] == \"upcoming\":\n",
    "            ophile.write(f\"* {p_name_key} \\n\")\n",
    "    ophile.write(f\"\\n\\n## Completed For Fiscal Year \\n\\n\")\n",
    "    ## sections for this\n",
    "    # workshop section\n",
    "    ophile.write(f\"\\n\\n### Workshops/Trainings \\n\\n\")\n",
    "    section_fill(dc,ophile,\"complete\",\"workshop\")\n",
    "    # collabs\n",
    "    ophile.write(f\"\\n\\n### Completed Projects/Collaborations \\n\\n\")\n",
    "    section_fill(dc,ophile,\"complete\",\"collaboration\")\n",
    "    #infra\n",
    "    ophile.write(f\"\\n\\n### Infrastructure Developed \\n\\n\")\n",
    "    section_fill(dc,ophile,\"complete\",\"infrastructure\")\n",
    "    #protocols and analysis\n",
    "    ophile.write(f\"\\n\\n### Protocols and Analysis Developed \\n\\n\")\n",
    "    return ophile\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def section_fill(dc,ophile,status,typ):\n",
    "    for p_name_key in dc:\n",
    "        deets = dc[p_name_key]\n",
    "        if deets[\"status\"] == status and deets[\"type\"] == typ:\n",
    "            ophile.write(f\"* {p_name_key} \\n\")\n",
    "            #print(deets)\n",
    "            if status == \"complete\":\n",
    "                links = deets['links']\n",
    "                for link in links:\n",
    "                    ophile.write(f\"\\t * {link} \\n\")\n",
    "\n",
    "clear_output(wait=True)\n",
    "result = run()\n",
    "result.seek(0)\n",
    "md(result.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.seek(0)\n",
    "now = datetime.datetime.now() - datetime.timedelta(days=3)\n",
    "with open(f\"{now:%Y}-{now:%m}-{now:%d}-Data-Vis-Weekly.md\",\"w\") as phile:\n",
    "    phile.write(result.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "import shutil\n",
    "#import python_quick\n",
    "\n",
    "with open('first_doc.yaml','r') as phile:\n",
    "    contents = yaml.full_load(phile)\n",
    "\n",
    "def fill_gaps():\n",
    "    ## this is intended to add other elements to the detailed_collection section\n",
    "    dc  = contents['detailed_collection']\n",
    "    attrs = contents['attributes']\n",
    "    for name in contents['names']:\n",
    "        dc_ele = dc.get(name.title(),-1)\n",
    "        ## check whether we have a project by this name yet\n",
    "        if dc_ele != -1:\n",
    "        ## this would be where we make sure all the attributes are present\n",
    "            for attr in attrs:\n",
    "                if dc_ele.get(attr,-1) == -1:\n",
    "                    dc_ele[attr] = None\n",
    "        ## if not \n",
    "\n",
    "        if dc_ele == -1:\n",
    "            dc[name.title()]={attr:None for attr in contents[\"attributes\"]}\n",
    "\n",
    "\n",
    "    \n",
    "def save_contents() :\n",
    "    backups = [f for f in os.listdir() if \"backup\" in f]\n",
    "    with open(\"first_doc.yaml\",\"w\") as phile:\n",
    "        yaml.dump(contents,phile)\n",
    "    ## this gives us actual empty strings for ease\n",
    "    with open(\"first_doc.yaml\",\"r\") as phile:\n",
    "        text_with_nones = phile.read()\n",
    "    correct_text = text_with_nones.replace(\"null\",\"\")\n",
    "    shutil.copy(\"first_doc.yaml\",f\"first_doc_backup_{len(backups) +1}.yaml\")\n",
    "    with open(\"first_doc.yaml\",\"w\") as phile:\n",
    "        phile.write(correct_text)\n",
    "\n",
    "def build_requests_from_yaml():\n",
    "    # pen the yaml\n",
    "    with open(\"first_doc.yaml\",\"r\") as phile:\n",
    "        structured_doc = yaml.full_load(phile)\n",
    "    # create a string\n",
    "    result_string = \"\"\n",
    "    # parse the yaml\n",
    "    dc =  structured_doc[\"detailed_collection\"]\n",
    "    for project_entry in dc:\n",
    "        result_string += f\"*{project_entry}*\\n\\n\"\n",
    "        pe = dc[project_entry]\n",
    "        ## go over all the individual attributes of project and add that to the result string\n",
    "        for attr in pe:\n",
    "    # add things with the correct headers to the string\n",
    "            result_string += f\"---{attr}---\\n\\n{pe[attr]}\\n\\n\"\n",
    "\n",
    "\n",
    "    # then return\n",
    "    return form_request(result_string)\n",
    "\n",
    "def form_request(text):\n",
    "    requests = [\n",
    "         {\n",
    "            'insertText': {\n",
    "                'location': {\n",
    "                    'index': 1,\n",
    "                },\n",
    "                'text':text \n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    return requests\n",
    "\n",
    "\n",
    "\n",
    "def send_to_gdocs(doc_id,requests):\n",
    "    service = python_quick.build_service()\n",
    "    service.documents().batchUpdate(documentId=doc_id,body={'requests':requests}).execute()\n",
    "\n",
    "\n",
    "def full_run():\n",
    "    fill_gaps()\n",
    "    save_contents()\n",
    "    #document_id =\"1HLsxu3P6C43GiS3qCAOgv3ZWZcN7Tept4oSdOdR2lIU\" \n",
    "    #req = build_requests_from_yaml()\n",
    "    #send_to_gdocs(document_id,req)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_gaps()\n",
    "save_contents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
