attributes:
- type
- status
- description
- updates
- dates
- contacts
- newUpdates
- links
detailed_collection:
  3D & Vr Retrofit Azlive:
    contacts: null
    dates: null
    description: null
    links:
    - https://rtdatavis.github.io/#retrofitAZLIVE
    newUpdates: false
    status: complete
    type: collaboration
    updates: null
  Advice For Thesis Defense Visualizations, Sabrina Nardin:
    contacts: null
    dates: null
    description: null
    links: null
    newUpdates: null
    status: null
    type: null
    updates: null
  Argonne Gpu Hackathon:
    contacts: null
    dates: null
    description: null
    links:
    - https://drive.google.com/file/d/1yzTyizIMLxRXabMTQgk7KzECsVYHrXOf/view?usp=sharing
    newUpdates: false
    status: Complete
    type: infrastructure
    updates:
    - - Got email that due to limited space our team and its proposed project weren't
        admitted
      - it's ok, I extended a webgpu rust boid simulator example and have it working
        on exosphere so perhaps I got something similar to the experience of the hackathon
        from that
      - https://drive.google.com/file/d/1yzTyizIMLxRXabMTQgk7KzECsVYHrXOf/view?usp=sharing
    - - Should hear from the organizers about whether we are admitted this week
    - - Blake asked if he could join, so I spoke with organizers again
    - - Dima asked if he could join the team so I wrote to the organizers to update
        our roster and they allowed it
    - - Submitted an application to participate in the Argonne GPU hackathon which
        takes place at the end of april
      - Team mates are Sara Willis, Chris Reidy, and Abby Collier
      - Our project is to produce a gpu accelerated flocking simulation that we can
        remotely visualize from a demo created to run only on a single cpu
      - Waiting on updates about our application
  Autamus Web Interface:
    contacts: null
    dates: null
    description: null
    links:
    - https://rtdatavis.github.io/#autamus_interface
    newUpdates: false
    status: complete
    type: infrastructure
    updates: null
  Bio5 Virtual Reality Tour:
    contacts: null
    dates: null
    description: null
    links:
    - https://rtdatavis.github.io/#bio5-vr-tour
    newUpdates: false
    status: complete
    type: collaboration
    updates: null
  Biosphere 2 Biosystems Visualization Collaboration:
    contacts: null
    dates: null
    description: null
    links: null
    newUpdates: true
    status: active
    type: collaboration
    updates:
    - - Fixed issues with converting vtu to obj!
      - Apparently issues stemmed from using 0 based counting in the obj face indices
      - Gave Omani  full folder of simulation results to work with
      - Started email chain with Developers at Open Root Sim about how to change the
        simulation parameters to create different plant root systems
      - I believe we won't get very far with this because they only focus on a few
        model plants and nothing bigger than a corn plant
      - Looked into L systems for generating artificial root structures, but it would
        be great to get scans of some much bigger plants
      - Omani started working on the VFX of animating particles traveling along the
        outsides of the mesh, but I think that's going to take time
    - - Still have significant issues converting the .vtu data to .obj
      - Even branched out to looking into the .ply format which I could then skin
        with blender later on
      - Small breakthrough related to discovering Paraview (which opens .vtu without
        issue) can export to gltf, but so far there isn't any clear way to automate
        this process
      - Even the pyparaview doesn't include much information about how to do this.
      - Spent more time looking into using the python VTK package to export
      - Researched writing L-Systems for synthetic branching strutures, and created
        a Rust Package to generate the L-System Axiom, and then wrote a parser that
        places points along the structure
      - Can view the results in Meshlab by importing .xyz formatted point cloud https://drive.google.com/file/d/1pJUg8obP_yyV05M8ESPK11xaVZUsyNnI/view?usp=sharing
    - - Met with Omani
      - Started working on the vfx out of unreal engine
      - There doesn't seem to be many easy ways to control the speed at which some
        effects propagate
      - Uploaded Open Root Sim to Jetstream and ran a bunch of sample simulations
        to give us root meshes to work with
      - Spent most of my time re-writing the .vtu to .obj script
      - Facing a really annoying bug in which there's an extra face at the end of
        each triangle strip, but there's no clues as to how to make sure I'm indexing
        the correct number of vertices
      - Once I have this worked out I can send things along to Omani
    - - Met with Omani
      - She was able to present some of her previous examples of biological scenes
        using unreal engine, super impressive
      - Plan is to make use of unreal's effects bound to wireframe models
      - I'll now try to produce a large number of converted meshes that she can try
        to import for running various types of VFX on
    - - Produced multithreading rust program that can do our "point to texture" conversion
      - from here I generated a brief example animation to demonstrate how we can
        use these textures with particle system visualizations
      - https://drive.google.com/file/d/13mIKrDNFu6SYvQSZCQxqFJnntc7HCl0y/view?usp=sharing
      - Aaron Bugaj notified us that the green fund is no longer a viable option for
        funding the media vis walls grant
      - Treating this year as a prototype of the program for working with students
        that have Biological System visualizations they want to do
    - - Started working on exploring unreal engine offerings related to our eventual
        visualization
      - Omani says the mist engine might be what we need for particle systems?
      - Created https://repl.it/@baylyd/quadtreeroot#script.js ,https://quadtreeroot.baylyd.repl.co/
      - Started working on Numpy method of calculating Luminosity of texture based
        on the distance that pixel lies from the nearest root point
      - Will use this texture for particle movement against or with value gradient
      - Ran into memory limit for certain sections of the root system on a Jetstream
        allocation
    - - Omani now has DCC status, which is great
      - Met and she got unreal engine installed on the machine that is more stable
        than the laptop
      - She's going to continue to brush up on her python
      - I'm going to try to create the first 3D texture of our first root so that
        we can use other programs than p5.js to do some of our first animated visualizations
    - - Succeeded at parsing the converted .vtu file into a mesh surrounding the points
        of the root simulation
      - Started a small example openprocessing sketch to explain the work to others,
        and myself at a later date
    - - Made more progress on understanding the .vtu file format and its layout of
        data, useful for visualizing the results of Open Root Sim
      - Began work with wireframe visualization of Zea Maize root development
  Bryan Carter Photogrammetry:
    contacts: null
    dates: null
    description: null
    links: null
    newUpdates: false
    status: upcoming
    type: consult
    updates:
    - - Met Bryan last week for a Metashape Demo
      - Talked about how access might work with the HPC
      - Need to explore the setup of Tyson's license inside the HPC environment
      - Discussed using UA's Apporto as a means of getting his studentt up to speed
    - - Tyson and Bryan were able to meet, but I could attend
      - Have a meeting with Bryan set for first week of March to discuss HPC and Metashape
        workflows
    - - Met and discussed array of different upcoming potential partnerships with
        the new center for digital humanities.
      - Potential project to explore using the Nvidia Omniverse for streaming the
        results of HPC calculations/render to center for digital humanities
      - Discussed meeting with Tyson to get started learning to use Metashape for
        his photogrammetry needs
      - Discussed using jetstream allocations instead of their AWS accounts to provide
        on demand access to media for their research projects from user's phones (didn't
        go into details about this)
  Collaboration With Techcore'S Summer Internship:
    contacts: null
    dates: null
    description: null
    links: null
    newUpdates: null
    status: null
    type: null
    updates: null
  Covid Retail Mitigation Web Scraping:
    contacts: null
    dates: null
    description: null
    links:
    - https://rtdatavis.github.io/#retailscraping
    newUpdates: false
    status: complete
    type: collaboration
    updates: null
  Data Visualization Roadshow With Jeff Oliver:
    contacts: null
    dates: null
    description: null
    links: null
    newUpdates: false
    status: active
    type: collaboration
    updates:
    - - Reaching out to the NSCS department to ask whether they have a graduate seminar
        which we can present to?
    - - Sent offer for presentation to Dianne Patterson in SLHS
      - She isn't able to offer actual class time for a presentation
      - Will have to decide with Jeff if we really don't want to pre-record something
        for them
      - Trying the NSCS department next
  Force Directed Biochem Networks:
    contacts: null
    dates: null
    description: null
    links:
    - https://rtdatavis.github.io/#biochem-networks
    newUpdates: false
    status: complete
    type: collaboration
    updates: null
  Has Faculty Collaborations With Holodeck:
    contacts: null
    dates: null
    description: null
    links: null
    newUpdates: false
    status: upcoming
    type: collaboration
    updates: null
  Independent Study Abby Collier:
    contacts: null
    dates: null
    description: null
    links:
    - https://openprocessing.org/user/255658?view=sketches
    - https://observablehq.com/@aecollier/sqrrules?ui=classic
    newUpdates: true
    status: active
    type: student
    updates:
    - - Met up and started working on custom materials
      - Had long discussion in the meeting cementing  the mental model of how the
        shaders are using different color channels to move particles
      - Also started working on how to use other texture inputs to help with particle
        spreading patterns
      - Had to rush into using uniform sampler2D types
      - As a result I made a short video recording explaining how to do modular arithmetic
        to calculate texture sample coordinates from instance id's  for each of our
        particles
    - - Met with Abby several times this week
      - The main focus of our time is on how to get her help with the touch designer
        visualizations for the show
      - Kay has requested a recreation of this effect https://www.youtube.com/watch?v=r9dd6csVZbk
        and I'm making it Abby's focus
      - Discussed feedback loops, texture lookups, neighbor queries, and soon we will
        talk about writing custom materials with shader code
    - - Met with Abby and started working on Touch designer
      - Wrote a section of Abby's outstanding senior nomination for Rich Thompson
        who is the primary Python lecturer for ISTA
      - Worked live through a Touch Designer network showing basic features such as
        CHOPs TOPs, parameter referencing, and feedback
      - Then did a very quick intro to programming particle systems as that will be
        the main thing we generate for the astro dance performance
    - - Met on friday to discuss final tweaks to the data visualization feature piece
      - Abby built a very nice heatmap displaying squirrel counts from the data set
        against the hectares they live in within central park
      - Worked on making legend for her graph, and how to add observational notes
        to the data
      - She will add some prose to outline the process of building the notebook but
        besides that we have completed our data visualization phase
      - Discussed with her the first resources she should use to get setup and oriented
        with Touch Designer!
      - From this point on she will be helping me produce material for the astronomy
        multimedia performance
    - - Met on friday
      - Discussed her feature piece for the data visualization section of the independent
        study
      - Worked on creating data that would lend itself to a heatmap representation
        of the squirrel population of central park
      - Additional experimentation in the direction of "details on demand" by providing
        interesting select "notes" from the data when a user mouses over a tile of
        the heatmap
      - Preparing for the wrap up week of the web visualization material
    - - Had our usual friday meeting
      - Discussed advanced interaction via geometric/semantic zooms, and data brushing
      - Spent the last 30 minutes discussing her feature piece for the data visualization
        section of the independent study
      - Have settled on doing a visualization of the Squirrel Census data hosted on
        Github
    - - Met up and answered questions related to previous week's exercises
      - discussed intricacies of D3 data binding
      - Covered the dynamics of adding and removing data without a key function
      - Moved on to some very basic code for reacting to user generated events such
        as "Mouse Over" "Mouse Out" and "Click"
    - - Met and took care of questions for the week
      - Moved along to using transitions and animations for our data visualizaions
      - Started looking at how D3 manages changes to the visualization's underlying
        data (enter,update,remove selections)
      - Assigned exercises for the week
      - Mentioned that she should attend the weekend workshop on using p5.js for website
        element creation, and she was one of the 5 people
    - - Met and addressed questions about the first week of using d3
      - Moved away from the template literal svg creation that is in vogue, and revisited
        the roots of d3 and DOM management with selections
      - Invited her to participate in the Argonne GPU hackathon as an extension of
        the datascience side of her independent study.
      - Worked on using the <g> element to organize our data in the graphics, and
        apply transforms to many elements at the same time.
      - Used the <g> elements to learn about how to create axes for our visualizations
    - - Met several times to try to troubleshoot the GLSL shader code on her feature
        p5.js sketch.
      - Shifted into our first week of the data visualization side of the independent
        study.
  Jason Hortin Holographic Dance Graduate Project:
    contacts: null
    dates: null
    description: null
    links: null
    newUpdates: false
    status: upcoming
    type: consult
    updates: null
  Judging The Data Visualization Challenge:
    contacts: null
    dates: null
    description: null
    links: null
    newUpdates: true
    status: active
    type: community
    updates:
    - - Started reviewing the entries, on track to finish this before the 28th
    - - Was notified by Jeff that this is the week to review the metric, and next
        week we will begin reviewing submissions
    - - Planning on approaching a few departments with the offer of a data visualization
        introductory piece for their grad students
      - Will start with my home department of Neuroscience and perhaps Speech Language
        and Hearing where I've done quite a bit of work already
    - - Met with Jeff Oliver and Kiri Carini to host a peer review session
      - Several individuals showed up with questions about whether their projects
        qualify
      - At the end we discussed options for Kiri to join our Data visualization roadshow
        for departments interested in geospatial visualizations
      - Reached out to Stephen Rains in the Department of Communication to offer a
        presentation for his upcoming Computational Social Science (CSS) mini conference,
        but he said the sessions were all full and they didn't need more presentations
      - He did send our email offer for intro to data visualization presentations
        to Joe Galaskiewicz who's the director of the CSS certificate program
    - - Spoke with Jeff Oliver about helping with a peer review session for individuals
        participating in the data visualization challenge
    - - Started going over the website for information related to my judging duties
    - - No updates this week
  Meeting With Tyson Swetnam To Discuss Containers And Remote Visualization:
    contacts: null
    dates: null
    description: null
    links: null
    newUpdates: false
    status: null
    type: null
    updates:
    - - Had recent break through using different technology, need to reach out to
        Tyson to discuss "NoMachine"
    - - Discussed approaches to using containers for remote visualization
      - Shared videos of my developments with him, waiting to hear feedback
      - Discussed option for teaching small special interest group session on container's
        equipped for remote visualization in the upcoming container bootcamp
      - He mentioned an opportunity to try out some proprietary nvidia remote desktop
        software, but we will only have 45 days to use it so I'm waiting for a less
        busy time of the semester to follow up
      - He was interested in the work of Florian Feldhaus and his xpra virtualgl EGL
        backend running out a docker container as a way to remove the X server dependency
        for accelerated remote visualization
  'Migrant Forensic Empathy Project: A Digital Borderlands Grant Initiative':
    contacts: null
    dates: null
    description: null
    links:
    - https://mfemigrantdeathmap.baylyd.repl.co/
    newUpdates: true
    status: active
    type: collaboration
    updates:
    - - Created realistic scaling version, but found that there's visual artifacts
        on the faces far from the camera, created SO issue for this but I imagine
        I will just have to downsize the mesh and alter other aspects to make the
        landscape scale feel appropriate
      - Spent a while re-writing the cross placement Rust code, so that the quad tree
        regions feature overlap
      - This ultimately makes the program less performant but the results are much
        more accurate
      - Performance benchmarking by isolating each individual entry of the scene and
        checking the fps
      - Learned that there doesn't seem to be any one piece causing performance issues
        which is comforting
      - Reached approximately the halfway point of allotted time for this project
        and there's still some big aspects I still have to implement
    - - Big push on this project this week
      - Wrote a Rust program which uses a quad tree structure to organize the 3d points
        of all our landscape vertices
      - When we convert the Medical Examiner's office gps data to mesh coordinates
        we can then query the x,z position of a cross against the quad tree and get
        optimized calculations for the y coordinate where the cross should be placed.
      - I then created a demo scene to show the mesh and the crosses placed in the
        landscape https://test-cross-placement.baylyd.repl.co/
      - <10% of crosses placed above mesh in the air, so this next week I'll have
        to do some test cases with a smaller mesh, and known placement points.
    - - Got data on lat-lng for migrant deaths along the border from Jonathan
      - Created simple webmap of this to help understand how many crosses may show
        up in the Aframe scene
      - https://mfemigrantdeathmap.baylyd.repl.co/
      - Unfortunately the previous student has cropped some of the digital elevation
        map (DEM) from its original bounding box so I can't make a function to map
        between the lat-lng range in the data and the x-z coordinates  of the landscape
        model
      - I had to recreate a Marching Cubes workflow to process the a URL to download
        a DEM into a 3D mesh
      - I'll be using the bounding box of this to convert the gps locations of the
        deaths into positions at which I need to place cross models in the landscape
    - - Recreated scene at larger scale
      - Troubleshooting some of the performance issues that are starting to drop us
        to 12fps
      - Experimented with raycasting for interaction with certain objects in the scene,
        performance droped to 5fps from this
      - Took screenshots to send to Jonathan with an update
    - - Heard back from Jonathan that the grants have been submitted
      - He put in a second grant to "recharge" for my time if comes through so we
        will probably have to talk about the finances of that again
    - - Generated first draft of content converted to Aframe https://drive.google.com/file/d/1GAPmOVXS1lgGaoFf_8nSHtGIbJh2XRxk/view?usp=sharing
      - Some issues listed here in my development issue tracker https://github.com/DevinBayly/digital_borderlands_conversion/projects/1
    - - First official week of development for this project.
      - Spent most of the time working on retrieving and modifying the landscape model
        of Southern AZ near "Oregon Pipe National Park"
      - Experimented with the Meshlab python api for programmatically editing/filtering
        large point clouds into meshes
      - Drafted process for systematically importing existing assets into Aframe
    - - Picked up an oculus rift from the library that I can use for 2 weeks
      - I'll try to record some of my previous unity build reviews so that I can refer
        to those as I start the Aframe conversion this way I don't have to rent the
        hardware multiple times
    - - Met with Jonathhan Crisman to get more details about the files that came with
        his folder of student work
      - Looks like i'll need to borrow an oculus in order to demo his scenes so that
        I can see what to create
      - Will reach out to Jen Nichols, and Jonathan  again to get help with this,
        Bryan Carter is where Jonathan got his temporary set so I might start there
        also
    - - Meeting with Jonathan Crisman to discuss beginning questions for converting
        his existing application to the Aframe WebVR platform so that future modification/maintenance
        is easier.
  Mt. Lemmon In Your Pocket-Creating A Virtual Reality Tour:
    contacts: null
    dates: null
    description: null
    links:
    - https://rtdatavis.github.io/#GIS_week2020
    newUpdates: false
    status: complete
    type: workshop
    updates: null
  Neuro Choropleth:
    contacts: null
    dates: null
    description: null
    links:
    - https://rtdatavis.github.io/#neuro-choro
    newUpdates: false
    status: complete
    type: collaboration
    updates: null
  Observablehq Portfolio Of Data Visualization:
    contacts: null
    dates: null
    description: null
    links: null
    newUpdates: false
    status: upcoming
    type: community
    updates: null
  Oyster Vibrio Literature Review:
    contacts: null
    dates: null
    description: null
    links: null
    newUpdates: false
    status: active
    type: collaboration
    updates:
    - - Met with Emily and created a leaflet webmap with her lit review GPS data
      - Will meet maximum 2 more times to help her get the website ready for her paper
    - - Emily had to reschedule to Tuesday
    - - Sent email to check on status of this as its been 6 months since their last
        update
      - Setup meeting this friday to discuss her needs and advise about data visualization
        techniques
  Presentation For Civil Engineering Department:
    contacts: null
    dates: null
    description: null
    links:
    - https://docs.google.com/presentation/d/15Z9zcxU4vIIgFPnKEcaGv9GH7JtjNdx4Xpnjec0EzEc/edit?usp=sharing
    newUpdates: false
    status: complete
    type: workshop
    updates:
    - - Met with Jeff
      - Debriefed Civil Engineering presentation
      - Created action items planning future presentations
      - Discussed Department of Sociology and Anthropology presentation with Kelsey
        Gonzalez for the 16th of April
      - Created planning document with our debrief thoughts, presentation opportunities,
        and content relevant to each individual audience
    - - Met with Jeff Oliver, ran through our presentation to practice
      - Discussed changes, sent the presentation to Joshua Levine to double check
        the attributions for material from his slides
      - Presented to the graduate civil engineers seminar
      - Jeff mentioned that it went so well that he wants to "take it on the road"
    - - Decided on the examples I'll be showing
      - One finite element method visualization of stress forces spreading through
        a model
      - Second one is going to be an Aframe scene of an intersection with car models
        steered by data coming from "CityFlow" the open source traffic simulator
    - - Met with Jeff Oliver last week to build outline for presentation.
      - Got OK from faculty Josh Levine to use material from his slides for the "why
        we do data visualization" and "best practices" portion of the presentation.
  Ray Tracing On The Hpc:
    contacts: null
    dates: null
    description: null
    links: null
    newUpdates: false
    status: upcoming
    type: collaboration
    updates: null
  Remote Visualization Infrastructure Development:
    contacts: null
    dates: null
    description: null
    links: null
    newUpdates: true
    status: active
    type: infrastructure
    updates:
    - - Met Peter Messmer of Nvidia's HPC remote visualization division at Nvidia
        GTC
      - Discussed several projects that I want to leverage their tool Omniverse for
      - Got positive feedback that streaming results to displays like CATalyst's big
        display walls or even Biosphere2 should be included in their  Omniverse Beta
        release that's out now
      - Met quite a few other individuals who will probably be able to assist with
        this going forward
      - Will be testing using Exosphere and my own local machines before looking into
        HPC -> Catalyst
    - - Created brief statement for Blake to submit to the All hands accomplishments
      - Met with Chris Reidy to discuss the newest developments
      - Gave a demo showing the 1.5 million particle attractor using Jetstream Exosphere
        and the NoMachine remote desktop
      - Started working on how we can use Vulkan on the HPC
      - Chris said he would try to install NoMachine on i18n17 so that we can test
        whether that fixes the `Incompatible Driver` error when running `VulkanInfo`
    - - Big breakthrough learning more webgpu with the Rust systems programming language
      - Now understand enough to create some of the simple visualizations I've produced
        in Touch Designer
      - This means a significant improvement in performance because its written almost
        from scratch in gpu modern (vulkan not opengl) graphics code
      - Ran demonstration on 3 different machines of particle system where the mouse
        was an attractor
      - On new desktop was able to run 15 million particles close to 60 fps https://drive.google.com/file/d/1yyVqGcrgrW1rjqE8DPML8LDsJVetj1h1/view?usp=sharing
        Using laptop as nomachine display for exosphere cloud instance with 1/4 of
        V100 was able to run 1.5million particles in realtime
      - Performance dropped on exosphere using 15 million particles
      - Video links https://drive.google.com/file/d/1JbMX0GnxqVZgED8vcfoNEKGmEeYaCPld/view?usp=sharing
        (1.5 million), https://drive.google.com/file/d/1zg-fUDU4cYLmW-bksi3GBwplzqWnTBj7/view?usp=sharing
        (15 million)
    - - Finished converting a working graphical simulation of flocking points
      - This is a quintessential n-body update algorithm that would be a good indication
        of the workflows capability for running compute tasks on the gpu and rendering
        the results in realtime
      - Will be testing this out on exosphere this week
      - If that's successful then I will work on getting the example setup on our
        HPC
    - - Succeeded in using Vulkan via NoMachine remote desktop running on subdivided
        V100 Nvidia GPU
      - Created a screen cast video explaining the setup steps and sent to Jeremy
        Fischer in charge of NSF's Exosphere
      - He's very excited and is going to use the video to create documentation for
        users interested in my workflow when Exosphere is released to the public
    - - Worked on Jeremy Fischer's exosphere Nvidia JS Ubuntu 18 instance
      - Worried that their Nvidia V100 gridded VGPU isn't going to actually work for
        Vulkan which will limit the access to modern graphics development that researchers
        can do in their instances
      - Uncertain whether this is going to predict whether Vulkan will work with our
        V100s and K80s since they aren't currently being subdivided into virtual GPUs
      - Will be trying all of my steps on Exosphere outside of singularity containers
        this week to determine if singularity is the problem
    - - See whether I can use the singularity containers in the HPC testing environment
        that Chris has setup on Ocelote
      - If that works out, transfer the containers to the exosphere GPU instances
        I have from Jeremy Fischer and test there
    - - Successfully configured new desktop to work as build environment for the singularity
        containers that will have remote visualization/advanced graphics capability
      - Did test with nvidia/vulkan (openGL's successor) and was able to get graphical
        windows from the vkcube, and all of the rust gfx-hal demos
    - - Received new desktop machine with Nvidia card inside
      - Started trying to develop containers for use with HPC remote visualization
      - Windows Subsystem for Linux 2 is stuck with certain Nvidia Utils like nvidia-smi
  Resbaz Organizer And Workshop Provider:
    contacts: null
    dates: null
    description: null
    links: null
    newUpdates: true
    status: active
    type: workshop
    updates:
    - - Built workshop Observable notebook
      - Created observable notebook conversion of Kate Isaac's Vega-lite data visualization
        workshop
      - Discussed with Blake what the process would be for adding videos to the resbaz
        youtube channel, it sounds like he'll take that on just because it sounds
        like access is a tricky subject
      - Setup next meeting with Chinmay for following wednesday
    - - Met with Chinmay Joshi
      - Discussed our todo items for getting the zoom links created
      - Discussed scripts to provide the helpers and the workshop presenters so that
        things go smoother than the last time that Chinmay attended
      - Discussed new approach to the recordings, and double checking on Accessibility
        strategies with Kelsey Gonzalez
    - - Met with Alex and planned our workshop
      - Will send outline to Ian Johnson who works at Observable and see what he thinks
      - Meeting with other Zoom and Youtube Coordinator Chinmay at somepoint to practice
        zoom and youtube upload
    - - Meeting with Alex Next week
      - More planning conversations on Trello regarding zoom usage
    - - Planning on trello
      - Discussing the needs for Zoom and how to use gather.town for community sessions
    - - Got access settings set correctly for Alex to modify the document
      - Discussing individual tasks with Chinmay for the Zoom and Youtube coordinators
    - - started working with Alex and Kate on a google doc to organize our plans for
        introducing ObservableHQ at the resbaz this year
      - connected with Fernando Rios' buddy Ian Johnson who works at Observable
    - - Met with rest of organizing group
      - Put myself down as one of the two youtube/zoom coordinators since that role
        is similar to how I'm helping the Women's hackathon
      - Pitched an ObservableHQ visualization workshop and Alex Bigelow is going to
        coteach and help with development
    - - Organizer meeting this week to discuss what workshops to offer, and other
        administrivia
  Social Vr Museum Capstone Student Project:
    contacts: null
    dates: null
    description: null
    links:
    - https://rtdatavis.github.io/#social-vr-museum
    newUpdates: false
    status: complete
    type: student
    updates: null
  Spring Break Covid Photo Maps:
    contacts: null
    dates: null
    description: null
    links:
    - https://rtdatavis.github.io/#spring-break-covid
    newUpdates: false
    status: complete
    type: collaboration
    updates: null
  Stellarscape Astronomy Multimedia Dance Performance:
    contacts: null
    dates: null
    description: null
    links: null
    newUpdates: true
    status: active
    type: collaboration
    updates:
    - - Switched gears in development for this project to curves instead of particle
        systems
      - Reviewed videos that Kay sent to me for inspiration
      - Spent time reading Fundamentals of Computer Graphics chapters on splines,
        Hermite cubics, and Bezier curves
      - Made a proof of concept GPU compute touch designer example of 100^2 lines
        interpolated to a level of detail around 1000 segments per line
      - Somehow this still ran at 60fps? Not going to argue with the results.
      - Setup meeting with Gustavo the director of the new Sensor Lab to discuss the
        sensor options we will have access to for the show
      - Researched and implemented a system for switching between running Visualizations
        within Touch Designer so that we can script the whole performance from beginning
        to end without being hands on
      - This will be ultimately better because its still pretty likely that we would
        press the wrong thing at the wrong time and create a technical difficulty
    - - Big meeting this week
      - Also heard back from Brant Robertson and Evan Schneider that we can use their
        Galaxy outflow simulation visualization for our show
      - This is such a cool looking effect, I don't know where it will fit in yet
        though
      - Ran into some big performance problems with Touch Designer, but their most
        recent update appears to fix things
      - Made demos for meeting with Hayley and Kay
      - Will do more live outside testing with them next monday
      - Still stuck on creating simple propagation effects
      - Watched new series of videos by Stanslav Glasov, but he didn't go into the
        subject I was looking for on how to generate point/line network effects in
        touch designer on the GPU
    - - Rapid prep for presentation of work with our dancer Hayley Meier
      - Spent the week working on all of our existing visualizations trying to incorporate
        feedback from Kay
    - - Fixed Gasoline errors
      - Ran AGORA Disc example which is Isolated Milky-Way Like Disk Galaxy  using
        pthread over 10 cores (took 2 days to complete)
      - Created 2 visualization workflows for this within Touch Designer, Volumetric
        renderer, Instanced particle system
      - The volumetric renderer was a useful technique to brush up on but suffered
        from 3D texture size limitations in touch designer
      - The instanced particle system will be a much better approach requiring less
        pre-processing (no 3D texture to create, just parsing a binary snapshot from
        gasoline) and doesn't have visual artifacts produced at certain angles
      - visual results https://drive.google.com/file/d/1KFpEVgSEkSh4ZxSClgoLPJEL_Cp3m9ik/view?usp=sharing
        (instanced particle system) , https://drive.google.com/file/d/1DkSOdYlJpbWoZqremOAbLzGY9XB7OwTb/view?usp=sharing
        (volumetric renderer)
    - - Produced first MONOCOLOR inspired geometric scenes
      - Spent time in the week working with derivative community to troubleshoot performance
        of the geometry shader, it appears that the radeon pro vega 56 card on the
        imac pro may not be as performant as we hoped
      - developed a visualization of particles driven by a vector field based on the
        mathematical operations curl and divergence and the mouse input
      - Converted fluid mechanics particle system to be driven by kinect depth sensor
        mode
      - Experimented with James Wadsley's SPH program "Gasoline", but cannot get past
        an error which comes up on the Jetstream cloud instance when running with
        pthread on 6 cpu cores
      - So far no suggestions from the developers on the github issue I created for
        this
    - - Produced particle system visualizations driven by fluid mechanics coupled
        to user input (mouse or microsoft kinect)
      - Created first particle system with interconnecting lines using Kay's audio
        input
      - Discussing presentation options with Win Burleson for the top down dancer
        on stage section of movement 1
      - Found second researcher James Wadsley who may be able to provide solar formation
        SPH (smoothed particle hydrodynamics) simulations
    - - Got commercial license for Touch Designer
      - Exploring the differences from the free version
      - Learning to use the geometry shader section of the opengl pipeline to change
        the primitives that I operate on from points to lines
      - Exploring and recreating the techniques used in MONOCOLOR, Latent Space and
        Fulldome show by Marian Essl https://derivative.ca/community-post/monocolor-latent-space-and-fulldome-environment
      - Hitting snags related to renders that are higher resolution than 1280x720
      - Discussing options for movement 1's camera setups with Win Burleson
    - - Met with Kay to do Space Engine Flythroughs with the new version of the program,
        using its built in recorder
      - She thinks that we have all the space footage that we need for the show now
      - Met with Lewis Humphrey of Tech Launch Arizona to discuss what license we
        need for the programs we use in the project, he says we are commercial and
        Kay will try to raise money to pay for Touch Designer commercial license (600$)
      - Deadline for visuals of the first movement was Friday, but not everything
        was complete
      - Created a Trello to better track my progress and Kay's suggestions
      - New deadline is the 18th to finish part 1, and the first of april to have
        the second movements visuals
    - - Met with Kay to discuss development of particle system behaviors
      - Had a second meeting with her in the week to test out whether my iMac Pro
        desktop is faster than the resources she has, appears a mixed result
    - - Met with Kay, shot footage of various nebulae (horse head, carina, orion,...)
      - Finished storyboard for first movement of performance
      - Win Burleson met with Tech Launch to discuss Licensing, but haven't heard
        the results of that meeting
  Tech Core Level Up Presentation Monday, Sept 28 2020:
    contacts: null
    dates: null
    description: null
    links:
    - https://rtdatavis.github.io/#techcoresept28
    newUpdates: false
    status: complete
    type: workshop
    updates: null
  Tech Core Level Up Presentation Tuesday, Mar 17 2020:
    contacts: null
    dates: null
    description: null
    links:
    - https://rtdatavis.github.io/#techcoremar20
    newUpdates: false
    status: complete
    type: workshop
    updates: null
  Virtualgl For Nvidia Accelerated Remote Hpc Visualizations:
    contacts: null
    dates: null
    description: null
    links:
    - https://rtdatavis.github.io/#virtualgl
    newUpdates: false
    status: complete
    type: infrastructure
    updates: null
  'Womens Hackathon: Visualization On The Web Workshop':
    contacts: null
    dates: null
    description: null
    links:
    - https://womenshackathon.arizona.edu/
    - https://www.youtube.com/channel/UCe1YiJ53o3qcayVs4cipeXA/videos
    - https://www.youtube.com/watch?v=VLwPOtqW8oM
    newUpdates: false
    status: complete
    type: workshop
    updates:
    - - Taught "Making art on the web with code" workshop one more time
      - Low attendance (4 people)
      - Tested using repl.it collaborative coding platform for teaching, proved a
        bit complex and prone to people accidentally deleting the entire program
      - Facilitated other needs with the discord chat such as sharing the youtube
        links when asked for
    - - Provided support for other workshop presenters
      - Assisted with questions related to presenation methods during the virtual
        hackathon
      - Helped upload a few different presenter's videos to the youtube channel
    - - Recorded my workshop on friday evening
      - Second hour on HTML/CSS started recording but didn't finish so will have to
        re-record and upload this week
      - Trouble shot issues with uploads of longer videos on saturday morning
      - Apparently the email notifications for participants didn't go out so I may
        be teaching this again next saturday
      - Had 4 people attend and taught about basic p5.js as well as how to use it
        to create webpage interfaces that can affect the visualizations
    - - Brainstorming and organizing material for my upcoming pre-recorded workshop
        on creative coding with p5.js
    - - Provided feed back to Jen on the website that has the schedule for the event
  Xpra And Singularity For Comprehensive Graphical Application Support On Hpc:
    contacts: null
    dates: null
    description: null
    links:
    - https://rtdatavis.github.io/#xprasingularity
    newUpdates: false
    status: complete
    type: infrastructure
    updates: null
names:
- Biosphere 2 Biosystems visualization Collaboration
- Stellarscape Astronomy Multimedia Dance Performance
- 'Migrant Forensic Empathy project: a Digital Borderlands grant initiative'
- Independent study Abby Collier
- Presentation for Civil Engineering Department
- Data Visualization Roadshow with Jeff Oliver
- Judging the data visualization challenge
- Remote visualization infrastructure Development
- Oyster Vibrio Literature Review
- Ray tracing on the HPC
- HAS Faculty collaborations with Holodeck
- COVID Retail Mitigation Web Scraping
- Autamus web interface
- Bryan Carter Photogrammetry
- 'Womens Hackathon: Visualization on the web workshop'
- ObservableHQ portfolio of Data Visualization
- Jason Hortin holographic dance graduate project
- Advice for thesis defense visualizations, Sabrina Nardin
- Collaboration with TechCore's Summer Internship
- Resbaz organizer and workshop provider
- force directed biochem networks
- neuro choropleth
- spring break COVID photo maps
- VirtualGL for Nvidia accelerated remote HPC visualizations
- Xpra and Singularity for comprehensive Graphical application support on HPC
- 3D & VR Retrofit AZLIVE
- BIO5 virtual reality tour
- social VR museum capstone student project
- Tech core level up presentation Tuesday, Mar 17 2020
- Tech core level up presentation Monday, Sept 28 2020
- Argonne GPU hackathon
- Mt. Lemmon in your Pocket-creating a virtual reality tour
- Meeting with Tyson Swetnam to discuss containers and remote visualization
